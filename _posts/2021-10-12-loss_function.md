---
title:  "손실함수(Loss Function)"

categories:
  - Machine Learning 
last_modified_at: 2021-10-12T08:06:00-05:00

---


손실함수란 이름 그대로 손실을 측정하는 함수이다.
여기서 손실이란 오차, 차이를 말한다.
"1과 3의 차이는 2이다." 같은 간단한 차이도 손실이라고 할 수 있다.
하지만 효율적으로, 효과적으로 손실을 측정해서 줄이기 위해 다양한 손실함수가 고안되었으며,
오늘은 간단하게 2가지만 소개하도록 할 것이다.
<br/>
<br/>
널리 쓰이는 손실함수에는 크게 2가지가 있다.
1. 평균 제곱 오차 (Mean Squared Error, MSE)
2. 교차 엔트로피 오차 (Cross Entropy Error, CEE)
<br/>
<br/>
먼저 평균 제곱 오차를 보겠다.
평균 제곱 오차 다음과 같이 정의한다. 

$Error = \frac{1}{2} \sum^{N}_{i=1} (y_i - t_i)^2$

우선 y와 t의 차이를 제곱한다.
제곱을 해줌으로서 빼는 순서는 관련이 없고 둘의 절대적 차이만을 나타내게 된다.
단순하게 둘의 차이를 구해서 제곱하는 손실함수이다.
제곱을 함으로서 차이가 커질수록 손실은 기하급수적으로 늘어난다.
<br/>
<br/>
다음으로 교차 엔트로피 오차를 보겠다.
교차 엔트로피 오차는 다음과 같다

$Error = - \sum^{N}_{i=1} t_i log_e y_i$

크로스 엔트로피 오차 또한 손실을 계산하는 수많은 손실함수 중 하나이다.
<br/>
<br/>
그런데, 여기서 의문이 생긴다.
평균 제곱 오차의 경우 직관적으로 손실을 측정한다는 것을 알 수 있다.
왜냐하면 손실(차이)를 계산하기 위해 두 값을 빼주는 단순한 형태를 취했기 때문이다.
여기서 추가적으로 한 것이라고는 제곱을 해서 값을 크게 만든 것,
그리고 1/2을 곱해준 것 뿐이다.
이렇게 평균 제곱 오차는 손실을 측정하는 방식이 간단하다.
<br/>
<br/>
하지만 크로스 엔트로피는 직관적으로 저 식이 무엇을 의미하는지, 어째서 사용되는지 이해가 되질 않는다.
이에 대한 설명은 조금 길어지므로 크로스 엔트로피에 대한 자세한 설명은 따로 글을 작성하도록 하겠다.
한가지 기억해야 할 것은 손실함수의 핵심은 차이를 수치화 한다는 것이다.
무슨 손실함수를 사용하던, 본질적으로 손실함수란 차이를 계산하는 것이다.
두 값의 차이를 측정하는 것이 왜 중요한지 후에 머신러닝을 관련해 다루면서 말하도록 하겠다.
