---
title:  "손실함수(Loss Function)"

categories:
  - Machine Learning 
last_modified_at: 2021-10-12T08:06:00-05:00

---

손실함수란 이름 그대로 손실을 측정하는 함수이다.
여기서 손실이란 오차, 즉 차이를 말한다.
"1과 3의 차이는 2이다." 같은 차이도 일종의 
손실이라고 할 수 있다.

하지만 효율적으로, 효과적으로 
손실을 측정해서 줄이기 위해 다양한 손실함수가 고안되었으며,
간단하게 2가지만 소개하도록 할 것이다.

널리 쓰이는 손실함수에는 크게 2가지가 있다.

1. 평균 제곱 오차 (Mean Squared Error, MSE)
2. 교차 엔트로피 오차 (Cross Entropy Error, CEE)


먼저 평균 제곱 오차를 보겠다.
평균 제곱 오차 다음과 같이 정의된다. 

$$
\begin{align} 
Error = \frac{1}{2} \sum^{N}_{i=1} (y_i - t_i)^2
\label{eq:label}
\end{align}
$$

우선 y와 t의 차이를 제곱한다.
제곱을 해줌으로서 빼는 순서는 관련이 없고 둘의 절대적 차이만을 나타내게 된다.
단순하게 둘의 차이를 구해서 제곱하는 손실함수이다.
제곱을 함으로서 차이가 커질수록 손실은 기하급수적으로 늘어난다.
<br/>
<br/>
다음으로 교차 엔트로피 오차를 보겠다.
교차 엔트로피 오차는 다음과 같다

$Error = - \sum^{N}_{i=1} t_i log_e y_i$

크로스 엔트로피 오차 또한 손실을 계산하는 수많은 손실함수 중 하나이다.
<br/>
<br/>
그런데, 여기서 의문이 생긴다.
평균 제곱 오차의 경우 직관적으로 손실을 측정한다는 것을 알 수 있다.
왜냐하면 손실(차이)를 계산하기 위해 두 값을 빼주는 단순한 형태를 취했기 때문이다.
여기서 추가적으로 한 것이라고는 제곱을 해서 값을 크게 만든 것,
그리고 1/2을 곱해준 것 뿐이다.
이렇게 평균 제곱 오차는 손실을 측정하는 방식이 간단하다.
<br/>
<br/>
하지만 크로스 엔트로피는 직관적으로 저 식이 무엇을 의미하는지, 어째서 사용되는지 이해가 되질 않는다.
이에 대한 설명은 조금 길어지므로 크로스 엔트로피에 대한 자세한 설명은 따로 글을 작성하도록 하겠다.
한가지 기억해야 할 것은 손실함수의 핵심은 차이를 수치화 한다는 것이다.
무슨 손실함수를 사용하던, 본질적으로 손실함수란 차이를 계산하는 것이다.
두 값의 차이를 측정하는 것이 왜 중요한지 후에 머신러닝을 관련해 다루면서 말하도록 하겠다.
