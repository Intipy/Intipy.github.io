---
title:  "퍼지 집합과 인공지능"

categories:

  - Machine Learning
last_modified_at: 2021-10-12T08:06:00-05:00

---


집합이란 소속 여부를 분명히 알 수 있는 것들의 모임이다.  
예를들어, "키가 180cm 이상인 학생들의 모임"은 집합이지만, "키가 큰 학생들의 모임"은 집합이 아니다. 
수학적 의미의 집합에서는 '애매함'이나 '모호함' 등이 없는, 객관적이고 논리적인 기준이 있어야 한다.

하지만 현실 세계는 논리적으로 명확하게 나누어지지 않은 것들이 많다.  
앞서 말한 "키가 큰 학생들"이 그 예이다.  
이렇게 명확하지 않은 소속성을 가진 것들의 모임을 퍼지 집합이라는 것을 이용해 표현한다.

여기서 소속 함수라는 것이 있는데, 이름처럼 어떠한 집합에 해당 원소가 소속된 정도를 나타내는 함수이다.  
확실히 소속되어 있다면 소속 함수의 값은 1이 되고 확실히 소속되지 않았다면 0이 된다.

$\mu_A(x) = 1$

위 식은 집합 A에 x가 소속될 가능성이 1, 즉 확실히 소속된다는 것이다. 
여기서 $\mu_A(x)$가 소속 함수이다. 

일반적인 집합의 경우에는 그 정의부터가 소속 여부가 확실힌 것들의 모임이므로 소속 함수의 값이 1 또는 0이다.  
소속되거나 소속되지 않거나 둘 중 하나인 것이다.

그리고 소속 함수의 값이 0 부터 1 사이의 실수값을 가질 때, 이 집합을 퍼지 집합이라고 한다.  
0 부터 1 사이라는 것은 소속된 정도가 확실하지 않으며 가능성으로 나타내어진다는 의미이다.

일반적인 집합의 경우에 소속 함수는 원소 x를 정의역으로 하고 소속 여부를 치역으로 한다. 
아래처럼 원소 x들의 집합 X가 정의역이며, 소속 가능성이 0 과 1 뿐이므로 0 과 1을 원소로 하는 유한 집합을 치역으로 한다.

$\mu_A: X \rightarrow \\{0, 1\\}$

그리고 퍼지 집합의 경우에 치역이 달라진다. 
아래처럼 0 이상 1 이하의 실수를 원소로 하는 무한 집합을 치역으로 한다.

$\mu_A: X \rightarrow \\{n \; \mid \;  0 \leq n \leq 1, \; n \in \mathbb{R} \\}$

이제 실제 소속 함수의 예시를 보겠다. 
아래는 집합 A = {x | x는 0과 가까운 수} 에 대하여 소속 함수를 정한 것이다. 

$\mu_A(x) = \frac{1}{1+x^2}$

x가 0에서 멀어질 수록 소속 함수의 값이 작아진다. 
이것을 아래처럼 그래프로 나타내보겠다. 

![](/assets/image/membership_function.jpg)

0은 "0과 가까운 수들의 모임"에 포함될 가능성이 1이다. 
0은 확실히 0과 가깝다고 말할 수 있기 때문이다. 
그리고 0에서 멀어질수록 점점 0과 가까울 가능성이 떨어지는 것을 볼 수 있다. 

인공지능도 사람의 지능을 모방하기 위해서는 이러한 방식이 필요하다.  
실제 사람의 생각은 명확히 나누어지지 않고 애매하거나 추상화, 또는 일반화된 방식으로 이루어진다.

사진 분류로 예를 들어보겠다. 
어떤 사진을 보여주고 그 사진이 강아지인지 고양이인지 맞추는 인공지능은 그 사진이 어떤 집합에 속하는지 분류한다.
강아지일 경우 사진은 강아지 집합에 속하고 고양이일 경우 고양이 집합에 속한다. 

현재 인공지능은 퍼지 집합이나 기타 퍼지 이론을 이용해 인간의 생각과 같은 애매한 정보를 다룰 수 있게 하려는 노력을 하고 있다. 
다중 분류(Multi Classification) 문제의 경우 소프트맥스 함수라는 것을 이용하는데, 이것은 어떤 데이터가 특정 집합에 속할 가능성을 확률로 나타내는 함수이다. 

$\sigma(a_k) = \frac{e^{a_k}}{\sum_{i = 1}^{n} e^{a_i}}$

$y_k = \sigma(a_k)$

위와 같이 입력을 지수로 두고 전체의 합으로 나누어줌으로서 어떤 값을 확률로 변환하는 함수이다.

흔히 딥러닝이라 부르는 인공지능은 인간의 뇌 구조를 모방한 인공신경망을 기반으로 한다. 
인공신경망은 입력과 출력이 있기 때문에 일종의 함수로 표현 가능하다. 
함수의 조건인 하나의 정의역 원소가 둘 이상의 공역 원소에 대응될 수 없다는 조건을 만족하기 때문이다. (강아지면서 고양이라는 예측은 없다.)

그리고 신경망을 함수로 나타낸 것을 $net(x)$라 하겠다. 
x는 입력으로, 사진을 분류한다면 x는 사진이 될 것이고 음성을 분류한다면 x는 음성일 것이다. 

이제 인공지능의 예측을 확률로 변환하기 위해 소프트맥스 함수를 이용하면 최종적인 예측은 아래처럼 된다. 

$output = \sigma(net(x))$

인공신경망과 소프트맥스 함수를 이용해서 분류를 했다. 
이제 위 식을 소속 함수로 하여 퍼지 집합을 나타낼 수 있다. 

$\mu_A(x) = \sigma(net(x))$

분류라는 것 자체가 어떤 집합에 속할 가능성을 구하는 것이므로, 인공신경망의 출력을 소속 함수값으로 볼 수 있는 것이다. 
퍼지 집합 A를 강아지의 집합이라 하고 x를 강아지 사진이라고 한다면 소속 함수값(신경망의 출력) $\mu_A(x) = \sigma(net(x))$는 1과 가까운 값이 나올 것이다. 
강아지 사진은 강아지의 집합에 포함될 가능성이 높기 때문이다. 

만약 강아지 사진이 $x_1, x_2, x_3 ... x_n$ 이렇게 많다고 하면 강아지의 집합 A는 아래와 같다. 

$A = {\mu_A(x_1)/x_1, \mu_A(x_2)/x_2, \mu_A(x_3)/x_3 ... \mu_A(x_n)/x_n}$








 












