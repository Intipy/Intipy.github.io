---
title:  "신경망(Neural Network)"

categories:
  - AI
last_modified_at: 2021-10-12T08:06:00-05:00

---


이전 글에서 말한 것처럼 단층 퍼셉트론으로는 XOR 문제를 해결할 수 없었다.

비단 XOR 뿐이 아니라, 복잡한 문제의 경우 단층 퍼셉트론으로는 한계가 있다.

이런 문제를 해결하기 위해 퍼셉트론을 층층히 쌓아서 만든 것을 다층 퍼셉트론(Multi Layer Perceptron, MLP)이라고 한다.

그렇다면 신경망은 무엇일까?

신경망 또한 뇌의 구조를 모방한 것이다.

뉴런, 혹은 그와 비슷한 것들을 쌓아서 여러 문제들을 모델링할 수 있도록 하는 것이다.

<br/>

그렇다면 신경망과 다층 퍼셉트론의 차이는 무엇인가?

자세한 내용은 나중에 다루도록 하고 간단하게 말하자면 신경망은 아주 넓은 범위에 해당한다.

급격히 발화하는 신경망, 합성곱 연산을 이용한 신경망, 순환하는 신경망 등등

신경망은 매우 다양하고 아주 복잡한 신경망들도 다수 존재한다.

하지만 우리가 이번에 다룰 다층 퍼셉트론은 모든 뉴런이 연결된 가장 간단한 구조의 신경망이라고 할 수 있다.

다층 퍼셉트론의 구조는 아래와 같다.

![](/assets/image/neuralnetwork.png)

복잡해 보이지만 이전 글에서 보았던 퍼셉트론을 여러개 쌓은 것이 전부이다.

마찬가지로 입력을 받고, 이전에 설명한 퍼셉트론의 연산 과정대로 계산한 후, 출력을 내보낸다.

그저 조금 더 계산이 복잡해지고, 다양한 문제를 풀 수 있다는 것이 차이점이다. 

신경망은 층(Layer)으로 구분되는데 이름 그대로 각각의 층이 쌓여서 이뤄진다.

위 사진에서는 입력층 - 은닉층 - 출력층 이러한 구조를 이루고 있다.

입력층에는 입력 뉴런이 4개, 은닉층에는 은닉 뉴런이 5개, 출력층에는 출력 뉴런이 1개가 있다.

마찬가지로 각 간선은 가중치를 가지고, 층마다 편향을 가진다.

<br/>

하지만 여기서 문제가 있다.

위 사진처럼 간단한(작은) 신경망도 가중치가 무려 25개가 있다.

만약 은닉층이 20개로 늘어나기만 해도 85개로 늘어난다.

실제로 쓰이는 신경망에서는 층이 최소 4개는 될 것이며 각 층의 뉴런이 적어도 몇백개를 넘는다. 

경우에 따라 수천개가 되는 경우도 있다.

이럴 경우에 가중치의 개수는 어마어마하게 늘어난다.

계산은 컴퓨터가 해주니 걱정 없다지만, 

우리가 이 계산을 간결하고 체계적으로 표현해야 일단 컴퓨터에게 계산하라고 시키던지 할 것이다.

우리가 퍼셉트론을 설명한 것처럼 식을 풀어쓰면

$y = x_1w_1 + x_2w_2 + x_3w_3+ x_4w_4 ... + b$

상상만 해도 엄청난 노동이다.

<br/>

하지만 행렬의 특성과 구조를 이용해서 아주 간단하게 표현이 가능하다.

$Y = X \cdot W + B$

이렇게 행렬의 곱으로 표현하면 간단하게 표현 가능하다.

그렇다면 이 가중치와 입력들을 어떻게 행렬로 표현했는지 보겠다.

![](/assets/image/2-3perceptron.png)

쉬운 이해를 위해 입력이 2개, 출력 3개인 간단한 퍼셉트론을 가져왔다.

출력과 입력에 붙은 라벨(첨자)은 굳이 설명할 필요가 없을 것이고,

가중치에서 $w_{ji}$는 $x_i$에서 $y_j$로 가는 가중치라는 의미이다.

i에서 j로 가는 것을 왜 ij라고 하지 않고 ji라고 하는가에 대한 답은 밑에서 하겠다.

먼저 하나하나 계산을 해보겠다.

$y_1 = x_1w_{11} + x_2w_{12} + b_1$

$y_2 = x_1w_{21} + x_2w_{22} + b_2$

$y_3 = x_1w_{31} + x_2w_{32} + b_3$

위와같이 계산이 된다.

<br/>

그렇다면 이제 행렬로 나타내보겠다.

<br/>

$$X = \begin{bmatrix} 
x_1\;x_2 
\end{bmatrix}$$

입력은 위와같이 1행 1열로 나타냈다.

<br/>

$$W = \begin{bmatrix} 
w_{11}\;w_{21}\;w_{31} \\
w_{12}\;w_{22}\;w_{32} 
\end{bmatrix}$$

가중치는 2행 3열의 행렬로 나타냈다.

<br/>

$$B = \begin{bmatrix} 
b_1\;b_2\;b_3
\end{bmatrix}$$

편향은 1행 3열의 행렬이다.

<br/>

이렇게 표현했다면 이제 간단하다. 

$$X \cdot W + B = \begin{bmatrix} 
x_1w_{11} + x_2w_{12} + b_1 \;\; x_1w_{21} + x_2w_{22} + b_2 \;\; x_1w_{31} + x_2w_{32} + b_3
\end{bmatrix}$$

입력 행렬과 가중치 행렬의 곱에 편향 행렬을 더했다. 

이 결과는 $y_1, \;y_2 \;y_3$와 일치한다.

즉, 아래와 같이 나타낼 수 있다.

$$Y = X \cdot W + B $$

$$ \begin{bmatrix} 
y_1 \; y_2 \; y_3
\end{bmatrix} = \begin{bmatrix} 
x_1\;x_2 
\end{bmatrix} \cdot \begin{bmatrix} 
w_{11}\;w_{21}\;w_{31} \\
w_{12}\;w_{22}\;w_{32} 
\end{bmatrix} + \begin{bmatrix} 
b_1\;b_2\;b_3
\end{bmatrix}$$

입력과 가중치, 편향을 행렬로 표현한 후에 곱했더니 행렬로 표현된 출력이 나온다.

이렇게 행렬의 곱으로 신경망의 연산을 간단하게 표현할 수 있다.

가중치 행렬에 대해 더 자세히 알아보겠다.

<br/>

<br/>

![](/assets/image/2-3perceptron.png)

$$W = \begin{bmatrix} 
w_{11}\;w_{21}\;w_{31} \\
w_{12}\;w_{22}\;w_{32} 
\end{bmatrix}$$

먼저, 가중치 행렬의 열은 출력과 대응된다.

입력 행렬의 행 벡터가 가중치 행렬의 3개의 열 벡터와 차례로 곱해져서 3개의 출력이 나오기 때문이다. (여기서 곱한다는 것은 벡터의 내적을 의미함.)

따라서 가중치 행렬의 1열은 1번째 출력으로 가는 가중치들, 2열은 2번째 출력으로 가는 가중치들, 3열은 3번째 출력으로 가는 가중치들이다.

<br/>

또한 가중치 행렬의 행은 입력에 대응된다.

앞서 말했듯이 입력 행렬의 행 벡터가 가중치 행렬의 열 벡터와 차례로 곱해지는데,

이 말은 입력 행렬의 행 벡터의 길이와 가중치 행렬의 열 벡터의 길이가 같다는 뜻이다. (내적하는 두 벡터의 길이이므로 같다.)

한 행렬에서, 열 벡터의 '길이'는 행 벡터의 '개수'와 같으므로 입력의 개수만큼 가중치 행렬의 행의 개수가 정해진다.

따라서 가중치 행렬의 행은 입력에 대응되는 것이다.

즉, 가중치 행렬의 1행은 1번째 입력과 곱해지는 가중치들, 2행은 2번째 입력과 곱해지는 가중치들이다.

<br/>

무엇과 무엇이 대응 관계인지 정리해보겠다.

1-1. 가중치 행렬의 행은 입력과 대응
1-2. 가중치 행렬의 1행은 1번째 입력과 곱해지는 가중치들, 2행은 2번째 입력과 곱해지는 가중치들

2-1. 가중치 행렬의 열은 출력과 대응
2-1. 가중치 행렬의 1열은 1번째 출력으로 가는 가중치들, 2열은 2번째 출력으로 가는 가중치들, 3열은 3번째 출력으로 가는 가중치들


가중치 행렬의 크기는 2×3 (2행 3열) 이다.

입력이 2개, 출력이 3개이므로 가중치 행렬이 올바른 것을 볼 수 있다.

 





